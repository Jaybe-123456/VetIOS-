# ========================================
# VetIOS Environment Configuration
# ========================================
# Copy this file to .env and fill in your actual values
# NEVER commit the .env file to version control

# ========================================
# VECTOR DATABASE - Pinecone Configuration
# ========================================
PINECONE_API_KEY=your-pinecone-api-key-here
PINECONE_ENV=gcp-starter
PINECONE_INDEX=vetios-index

# ========================================
# AI MODEL - Hugging Face Configuration
# ========================================
HUGGINGFACEHUB_API_TOKEN=your-huggingface-token-here

# ========================================
# FRONTEND - API Connection (for ui folder)
# ========================================
# For React frontend to connect to backend
VITE_BACKEND_URL=https://your-backend-service.onrender.com

# ========================================
# DATA SOURCES - PubMed/NCBI Configuration
# ========================================
# Required for accessing PubMed API
NCBI_EMAIL=your-email@example.com

# ========================================
# TEXT PROCESSING - Document Chunking
# ========================================
# Configure how documents are split for vector storage
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# ========================================
# BACKEND SERVER - FastAPI Configuration
# ========================================
# Server configuration (mainly for local development)
API_HOST=0.0.0.0
API_PORT=8000

# For production deployment (Render sets this automatically)
PORT=8000

# ========================================
# OPTIONAL - Additional Configuration
# ========================================
# Environment (development/production)
NODE_ENV=production

# Logging level
LOG_LEVEL=INFO

# Maximum tokens for AI responses
MAX_TOKENS=512

# Temperature for AI responses (0.0-1.0, lower = more focused)
AI_TEMPERATURE=0.2

# Embedding model
HF_EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
